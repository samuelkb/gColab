{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing depth\n",
    "\n",
    "We have learned two types of layers for neural networks, we began with convolutional layers wich detect regional patterns in an image using a series of image filters. We have seen how typically a ReLu activation function is applied to the output of these filters to standarize their output values. Then we learned about maxpooling layers, which appear after convolutional layers to reduce the dimensionality of our input arrays. These new layers, along with fully-connected layers, are often the only layers that we will find in CNNs.\n",
    "\n",
    "Let's discuse how to arrange these layers to design a complete CNN architecture, we will focus again on CNNs for image classification. In this case, our CNN must accept an image array as an input. Now, if we are going to work with messy real-world images, there is a complication that we haven't yet discussed.\n",
    "\n",
    "If we go online and collect thousands or million of images, it is pretty much guaranteed that they will all be different sizes. Similar to MLPs, the CNN we will discuss will require a fixed size input. So we have to pick an image size and resize all of our images to that same size before doing anything else. \n",
    "\n",
    "This is considered to be another pre-processing step, alongside normalization and conversion to a tensor datatype. It is very common to resize each image to be a square, with the spatial dimensions equal to a power of 2, or else a number that's divisible by a large power of two. \n",
    "\n",
    "We will be working with a dataset composed of images that have all been resized to 32x32 pixels. Recall that any image is interpreted by the computer as a 3D array. Color images had some height and width in pixels along with red, blue and green color channels corresponding to a depth of three. Gray scale images, while technically 2D, can also be thought of as having their own width and height and a depth of one.\n",
    "\n",
    "For both of these cases, with color or grayscale, the input array will always be much taller and wider than it is depth.\n",
    "\n",
    "Our CNN architecture will be designed with the goal of taking that array and gradually making it much deeper than it is tall or wide. Convolutional layers will be used to make the array deeper as it passes through the network, and maxpooling layers will be used to decrease the X, Y dimensions. As the network gets deeper, it is actually extracting more and more complex patterns and features that help identify the content and the objects in an image, and it is actually discarding some spatial information about features like a smooth background and so on that do not help identify the image. \n",
    "\n",
    "Let's go over a complete image classification CNN in detail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
